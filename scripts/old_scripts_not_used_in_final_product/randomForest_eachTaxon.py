#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Jun 25 16:07:46 2021

@author: jharrison
"""

#Trains a random forest with hyper parameter optimization for each line
#in a file that provides a list of taxa to model. 

#NOTE: if you get this warning: WARN: OMP_NUM_THREADS=None =>
#... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely
#Then set this env. variable: export OMP_NUM_THREADS=1

#Also to get this to work on Teton I had to load miniconda and make a new
#conda environment where I could install modules without problems. 
#I also had to add the conda forge channel to find certain modules.
#For reference, commands were: 
#module load  python/3.8.7 #perhaps not stricly neccessary to make env. but YOU DO want to make sure you are using
#the version of python you want before installing stuff or you will get a bunch of stupid errors
#because of pythonic compatibility woes
#module load miniconda3
#conda create --name py38 python=3.8
#conda config --add channels conda-forge
#conda activate py38
#conda install pandas -y
#conda install numpy -y #Do NOT load from the module list on TEton as it will cause you to switch back to python 2.7 and f things up.
#conda install sklearn -y
# conda install hyperopt -y
# conda install git pip #possibly needed to install hpsklearn from github without having issues due to user conflics between conda and pip
#  git clone https://github.com/hyperopt/hyperopt-sklearn.git
# #cd into cloned rep and then:
# pip3 install -e . --user
# conda install joblib -y
# conda install shap -y
# conda install re

import numpy as np
import pandas as pd
#Nonsense to force print entirety of a data frame
# pd.options.display.max_columns = None
# pd.options.display.max_rows = None
from hyperopt import tpe

from hpsklearn import HyperoptEstimator,random_forest_regression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score #,make_scorer, mean_squared_error
from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit

# from sklearn.model_selection import cross_val_score, KFold, StratifiedShuffleSplit, RandomizedSearchCV
# from sklearn.utils import check_random_state
import joblib
import shap
import re
from csv import writer
import sys 

#This wrapping in an if statement specifying __main__ was added
#because of an error. I think hypsklearn was importing portions of this script
#or some other script and so when run from the CLI this script was not seen as
#the main script and was defined but not run. See this page for more:
#https://www.geeksforgeeks.org/what-does-the-if-__name__-__main__-do/  
if __name__ == '__main__':
    #Pull integer from command line that will correspond to a line in 
    #file with otu names to make models for. 
    #Doing this way so that I can choose which OTUs to model more easily
    #See the script, "choosing_taxa_to_model_with_rf.py"
    
    focal_integer = int(sys.argv[1]) - 1 #because of Pythonic indexing, subtract one from value
    
    eval_runs = sys.argv[2]
    
    #for debugging
    focal_integer = 2
    eval_runs = 10
    
    possibles = pd.read_csv("./processedData/ITS_taxa_to_model_via_randomforest.csv")
    focal_taxon = possibles['taxa_its'][focal_integer]
    
    print(focal_taxon)
    
    #feature engineering was done in the neural net program
    X = pd.read_csv("./processedData/imputed_scaled_ITS_metadata.csv")
    
    #Bring in taxon proportions, these were wrangled in R after being generated by CNVRG
    taxa = pd.read_csv("./processedData/ITSp_estimates_wrangled_for_post_modeling_analysis_divided_by_ISD.csv")
    #taxa = pd.read_csv("./processedData/16sp_estimates_wrangled_for_post_modeling_analysis_divided_by_ISD.csv")
    
    #Subset taxa to just sample and the taxon taken from the command line
    taxa = taxa[['sample',focal_taxon]]
    
    # Remove diversity from features
    #X.columns.values
    X = X.loc[:,X.columns != 'shannonsISD']
    #Remember that the first 9 fields are not of interest. 
    
    #Need to ensure the samples are in the correct order
    #First a bit of wrangling to get a matchable sample name field
    #We will merge X and taxa instead of reording one of them
    X['compartment'] = X['EN'].map({1: 'EN', 0: 'EP'})
    #X['compartment'].value_counts()
    X['sample'] = X['plant.x'].str.cat(X['compartment'], sep='_')
    
    X_taxa = pd.merge(X, taxa, on='sample')
    
    #####################
    #Do train/test split#
    #####################
    
    #Figure out which indices correspond to the samples that had
    #the most of the taxon. These top 100 samples will be used for a 
    #stratified sampling, since they will include the samples that actually
    #had the particular microbe. 
    
    #Determine samples with most of microbe and then make a one hot encoded 
    #feature to stratify by
    N = 100
    res = sorted(range(len(X_taxa[focal_taxon])), key = lambda sub: X_taxa[focal_taxon][sub])[-N:]
    
    X_taxa['focal_taxon_onehot'] = 0
    X_taxa.loc[res, 'focal_taxon_onehot'] = 1
    
    X_taxa['brutal_hack'] = X_taxa["EN"] + X_taxa['focal_taxon_onehot']
    
    
    #Do stratified K fold sampling, but first split off some training data that I can use for the meta model
    tt_split = StratifiedShuffleSplit(n_splits=1, test_size=(0.2), random_state=(125))

    for train_index, test_index in tt_split.split(X_taxa, X_taxa['brutal_hack']):
        strat_train_set = X_taxa.loc[train_index]
        strat_test_set_fundamental = X_taxa.loc[test_index]
        
        strat_test_set_fundamental = strat_test_set_fundamental.drop(['focal_taxon_onehot', 'brutal_hack', 'sample',
         'region_site',
         'compartment',
         'Unnamed: 0',
         'X',
         'taxon.x',
         'region_site_plant',
         'plant.x',
         'forward_barcode',
         'reverse_barcode',
         'locus',
         'samplename'], axis=1)
    
    #Now we split the fundamental splits training data and build ten models from it. We will combine these models.
    ksplit = StratifiedKFold(n_splits=10, shuffle = True, random_state=(61))
    strat_splits = []
    
    #the split method takes the data as first argument then the variable to stratify on as the second argument
    #Recall the response are the proportions for a focal taxon
    
    for train_index, test_index in ksplit.split(strat_train_set, strat_train_set['brutal_hack']):
        strat_train_set = X_taxa.loc[train_index]
        strat_test_set = X_taxa.loc[test_index]
    
        #define response/predictor split
        #First drop various book keeping columns
        testsamples = strat_test_set['samplename']
        trainsamples = strat_train_set['samplename']
        
        strat_test_set = strat_test_set.drop(['focal_taxon_onehot', 'brutal_hack', 'sample',
         'region_site',
         'compartment',
         'Unnamed: 0',
         'X',
         'taxon.x',
         'region_site_plant',
         'plant.x',
         'forward_barcode',
         'reverse_barcode',
         'locus',
         'samplename'], axis=1)
        
        strat_train_set = strat_train_set.drop(['focal_taxon_onehot', 'brutal_hack', 'sample',
         'region_site',
         'Unnamed: 0',
         'compartment',
         'X',
         'taxon.x',
         'region_site_plant',
         'plant.x',
         'forward_barcode',
         'reverse_barcode',
         'locus',
         'samplename'], axis=1)
        
        X_array = np.array(strat_train_set.loc[:, strat_train_set.columns != focal_taxon])
        Y_array = np.array(strat_train_set[focal_taxon]).reshape(-1,1)
        
        Xtest_array = np.array(strat_test_set.loc[:, strat_test_set.columns != focal_taxon])
        Ytest_array = np.array(strat_test_set[focal_taxon]).reshape(-1,1)
        
        newsplit = [X_array, Y_array, Xtest_array, Ytest_array]
        strat_splits.append(newsplit)
        
    
    #Define model
    rf_model = RandomForestRegressor()
    
    #Train the model on the subsets of the data
    models = []
    scores = []
    
    for i in range(len(strat_splits)): 
        models.append(rf_model.fit(strat_splits[i][0], strat_splits[i][1].ravel()))
        yhat = rf_model.predict(strat_splits[i][2])
        scores.append(r2_score(yhat,strat_splits[i][3]))
    
    #Loop through models and combine all the trees
    def combine_rfs(models):
        for i in range(len(models)):
            models[0].estimators_ += models[i].estimators_
        models[0].n_estimators = len(models[0].estimators_)
        return models[0]

    comborf = combine_rfs(models)

    #predict to test data
    xtestf = np.array(strat_test_set_fundamental.loc[:, strat_test_set_fundamental.columns != focal_taxon])
    ytestf = np.array(strat_test_set_fundamental[focal_taxon]).reshape(-1,1)
    yhat = comborf.predict(xtestf)
    r2_score(ytestf,yhat)
    
    #QC
    #What is the average of scores? And, how is this not a built in method??
    # def Average(lst):
    #     return sum(lst) / len(lst)
    # Average(scores) #in test case the combo model did better
    
    ############################################
    # hyperparameter optimization, relic code #
    ###########################################
    
    #Since the model is an ensemble of ensembles hyper parameter tuning
    #doesn't make much sense now. E.g., these parameters would influence
    #The trees in the base models that have been combined. 
    #I have decided to not pursue tuning of all base models as i think this
    #might cross into very limited returns for time invested.
 
    
    ##############
    # save the model #
    ##############
    
    joblib.dump(comborf, './models/rf_model_object_' + focal_taxon)
    
    #To load use this syntax
    #model_random = joblib.load("PATH")
    
    
    from sklearn.inspection import permutation_importance
    import time
    start_time = time.time()
    result = permutation_importance(
        comborf, 
        xtestf, 
        ytestf, 
        n_repeats=10, 
        random_state=42, 
        n_jobs=2)
    
    elapsed_time = time.time() - start_time
    print(f"Elapsed time to compute the importances: "
      f"{elapsed_time:.3f} seconds")
    list_of_labels = strat_test_set_fundamental.columns[strat_test_set_fundamental.columns != focal_taxon]

    forest_importances = pd.Series(result.importances_mean, index=list_of_labels)


    ##############
    #SHAP values
    ############
    
    # Create Tree Explainer object that can calculate shap values
    # explainer = shap.TreeExplainer(comborf)
    
    # shap_values = explainer.shap_values(xtrainf)
    
    # shap.summary_plot(shap_values, 
    #                   X_array,
    #                   feature_names=list_of_labels)
    
    # #Extract SHAP values and then remove some features and try rerunning model
    # shapValues = pd.DataFrame(shap_values, columns=list_of_labels, 
    #                           index = trainsamples)
    
    # #write SHAP values to disk. 
    # shapValues.to_csv(path_or_buf=("./models/shap_values_randomforest_" + focal_taxon + ".csv"))
    
    # ###############################################
    # #Feature removal following SHAP value creation
    # ###############################################
    
    # #Figure out unimportant features
    # duds = shapValues.sum(axis = 0)[abs(shapValues.sum(axis = 0)) < 0.2]
    
    # #Here I am searching for taxa in this list of useless features, bc
    # #I WANT to keep all taxa
    # l = duds.index.tolist()
    # r = re.compile(r'.*\s+.*')
    # newlist = list(filter(r.match, l))
    # #print(newlist)
    
    # #Remove taxa from list of features to remove. Thus keeping taxa.
    # for i in newlist:
    #     l.remove(i)
    
    # #Now we have a list, l, that has features to be removed. Lets remove them and rerun the model 
    # ###########################################
    # # Running model again after removing useless features #
    # ###########################################
    
    # #remove a few things, just to be safe. 
    # del X, X_array, Y_array, Ytest_array, split, strat_test_set, strat_train_set
    
    # #Note that the reason to do this is because if one has a bunch of shit features
    # #they will get picked during feature bagging while training the model, thus
    # #diluting the effect of the better features. 
    
    # X = pd.read_csv("./processedData/imputed_scaled_ITS_metadata.csv")
    
    # #Remove features that we have deemed not helpful
    # for i in l:
    #     X.drop(i, inplace=True, axis=1)
    
    # # Remove diversity from features
    # #X.columns.values
    # X = X.loc[:,X.columns != 'shannonsISD']
    
    # if 'EN' in X.columns:
    #     X['compartment'] = X['EN'].map({1: 'EN', 0: 'EP'})
    #     X['sample'] = X['plant.x'].str.cat(X['compartment'], sep='_')
    # else:
    #      X['sample'] = X['plant.x']
    #      #bc compartment not included have to strip it off the sample field for merge
    #      taxa['sample'].replace(to_replace="_E[NP]", value="", regex=True, inplace=True)
         
    # X_taxa = pd.merge(X, taxa, on='sample')
    
    # N = 100
    # res = sorted(range(len(X_taxa[focal_taxon])), key = lambda sub: X_taxa[focal_taxon][sub])[-N:]
    
    # X_taxa['focal_taxon_onehot'] = 0
    # X_taxa.loc[res, 'focal_taxon_onehot'] = 1
    
    # #Code from Geron. 
    # if 'EN' in X.columns:
    #     X_taxa['brutal_hack'] = X_taxa["EN"] + X_taxa['focal_taxon_onehot']
    #     split = StratifiedShuffleSplit(n_splits=1, test_size=(0.3), random_state=(666))
    #     for train_index, test_index in split.split(X_taxa, X_taxa['brutal_hack']):
    #         strat_train_set = X_taxa.loc[train_index]
    #         strat_test_set = X_taxa.loc[test_index]
    # else: 
    #     split = StratifiedShuffleSplit(n_splits=1, test_size=(0.3), random_state=(666))
    #     for train_index, test_index in split.split(X_taxa, X_taxa['focal_taxon_onehot']):
    #         strat_train_set = X_taxa.loc[train_index]
    #         strat_test_set = X_taxa.loc[test_index]
    
    # #define response/predictor split
    # #First drop various book keeping columns
    # testsamples = strat_test_set['samplename']
    # trainsamples = strat_train_set['samplename']
    
    # strat_test_set = strat_test_set.drop(['focal_taxon_onehot', 'sample',
    #  'region_site',
    #  'Unnamed: 0',
    #  'X',
    #  'taxon.x',
    #  'region_site_plant',
    #  'plant.x',
    #  'forward_barcode',
    #  'reverse_barcode',
    #  'locus',
    #  'samplename'], axis=1)
    
    # strat_train_set = strat_train_set.drop(['focal_taxon_onehot', 'sample',
    #  'region_site',
    #  'Unnamed: 0',
    #  'X',
    #  'taxon.x',
    #  'region_site_plant',
    #  'plant.x',
    #  'forward_barcode',
    #  'reverse_barcode',
    #  'locus',
    #  'samplename'], axis=1)
    
    # if 'brutal_hack' in strat_train_set.columns:
    #     strat_train_set = strat_train_set.drop(['brutal_hack', 'compartment'], axis=1)
    #     strat_test_set = strat_test_set.drop(['brutal_hack', 'compartment'], axis=1)
    
    # X_array = np.array(strat_train_set.loc[:, strat_train_set.columns != focal_taxon])
    # Y_array = np.array(strat_train_set[focal_taxon]).reshape(-1,1)
    
    # Xtest_array = np.array(strat_test_set.loc[:, strat_test_set.columns != focal_taxon])
    # Ytest_array = np.array(strat_test_set[focal_taxon]).reshape(-1,1)
    
    # strat_test_set.shape  
    # strat_train_set.shape
    
    # # refit the model
    # model_random_reducedFeatureSet = HyperoptEstimator(regressor=random_forest_regression('random_forest_regression'),
    #                           algo=tpe.suggest, 
    #                           max_evals=int(eval_runs), 
    #                           trial_timeout=30)
    
    # # perform the search
    # model_random_reducedFeatureSet.fit(X=X_array, y=Y_array.ravel())
    
    # joblib.dump(model_random_reducedFeatureSet, './models/rf_model_object_reducedFeatureSet' + focal_taxon)
    
    # ##############
    # #SHAP values
    # ############
    
    # # Create Tree Explainer object that can calculate shap values
    # explainer = shap.TreeExplainer(model_random_reducedFeatureSet.best_model()['learner'])
    
    # shap_values = explainer.shap_values(X = X_array)
    # list_of_labels = list(strat_train_set.loc[:, strat_train_set.columns != focal_taxon].columns)
    
    # # shap.summary_plot(shap_values, 
    # #                   X_array,
    # #                   feature_names=list_of_labels)
    
    # # #Extract SHAP values and then remove some features and try rerunning model
    # shapValues = pd.DataFrame(shap_values, columns=list_of_labels, 
    #                           index = trainsamples)
    
    # #write SHAP values to disk. 
    # shapValues.to_csv(path_or_buf=("./models/shap_values_randomforest_reducedFeatureSet" + focal_taxon + ".csv"))
    
    # #Write the taxon and new r2 to the results file
    # yhat = model_random_reducedFeatureSet.predict(Xtest_array)
    
    # r2_reduced = r2_score(Ytest_array,yhat)
    # r2_reduced
    
    # List=[focal_taxon,'full model',r2,'reduced model', r2_reduced]
      
    # # Open our existing CSV file in append mode
    # # Create a file object for this file
    # with open('./models/randomForest_results_its.csv', 'a') as f_object:
      
    #     # Pass this file object to csv.writer()
    #     # and get a writer object
    #     writer_object = writer(f_object)
      
    #     # Pass the list as an argument into
    #     # the writerow()
    #     writer_object.writerow(List)
      
    #     #Close the file object
    #     f_object.close()

